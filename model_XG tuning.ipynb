{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-12 20:55:06,052] A new study created in memory with name: no-name-3302fc05-b09c-43d9-addb-bdfbcbfc3104\n",
      "[I 2024-04-12 20:55:07,000] Trial 0 finished with value: -0.2523047175646897 and parameters: {'n_estimators': 544, 'max_depth': 15, 'learning_rate': 0.18097690090772048, 'min_child_weight': 20, 'subsample': 0.8405345444512003, 'colsample_bytree': 0.33181646191820147}. Best is trial 0 with value: -0.2523047175646897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'n_estimators': 544, 'max_depth': 15, 'learning_rate': 0.18097690090772048, 'min_child_weight': 20, 'subsample': 0.8405345444512003, 'colsample_bytree': 0.33181646191820147}\n",
      "RMSE: 324.9420249959768\n",
      "MAE: 211.52565375434028\n",
      "R^2: 0.5528294816380489\n",
      "Adjusted R^2: 0.3441499064024717\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBRegressor\n",
    "import optuna\n",
    "import joblib\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('filtered_data.csv')\n",
    "\n",
    "# Preprocessing\n",
    "X = data.drop('Price', axis=1)\n",
    "y = data['Price']\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Define a preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Splitting the data into training and test sets for final evaluation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 1, 2000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 20),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 0, 20),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.1, 1.0)\n",
    "    }\n",
    "\n",
    "    model = XGBRegressor(**param)\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('model', model)])\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scores = cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='r2', n_jobs=-1)\n",
    "    r2_mean = np.mean(scores)\n",
    "    return -r2_mean  # Return the negative R^2 to maximize it\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=1)  # You can adjust the number of trials\n",
    "\n",
    "# Best hyperparameters\n",
    "print(f\"Best hyperparameters: {study.best_trial.params}\")\n",
    "\n",
    "# Train the model with the best parameters\n",
    "best_params = study.best_trial.params\n",
    "best_model = XGBRegressor(**best_params)\n",
    "best_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                ('model', best_model)])\n",
    "\n",
    "best_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate on the test set\n",
    "y_pred = best_pipeline.predict(X_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "n = len(y_test)\n",
    "p = X_test.shape[1]\n",
    "adjusted_r2 = 1 - ((1 - r2) * (n - 1) / (n - p - 1))\n",
    "\n",
    "# Performance Metrics\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"R^2: {r2}\")\n",
    "print(f\"Adjusted R^2: {adjusted_r2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib\n",
    "# best_pipeline.fit(X_train, y_train)\n",
    "# # Save the trained model to disk\n",
    "# joblib.dump(best_pipeline, 'best_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "loaded_model = joblib.load('best_model.joblib')\n",
    "# Re-create the pipeline with the loaded model\n",
    "loaded_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                  ('model', loaded_model.named_steps['model'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           feature  importance\n",
      "4              Number of Bathrooms    0.298964\n",
      "2                            Rooms    0.219700\n",
      "7                      Size (sqft)    0.078517\n",
      "1              Property Type_House    0.071104\n",
      "6                        Longitude    0.054869\n",
      "0          Property Type_Apartment    0.044569\n",
      "12  Time to Nearest Police Station    0.039564\n",
      "13           Time to Nearest Store    0.035461\n",
      "14        Time to Nearest Pharmacy    0.032957\n",
      "11        Time to Nearest Hospital    0.030542\n",
      "8                       Walk Score    0.026786\n",
      "5                         Latitude    0.025818\n",
      "10                      Bike Score    0.021546\n",
      "9                    Transit Score    0.019603\n",
      "3                     Den Included    0.000000\n"
     ]
    }
   ],
   "source": [
    "def get_feature_names(column_transformer, input_features):\n",
    "    # This will hold the final names of the features\n",
    "    output_features = []\n",
    "\n",
    "    # Go through all the transformers in the ColumnTransformer\n",
    "    for transformer_name, transformer, feature_indices in column_transformer.transformers_:\n",
    "        if transformer_name == 'remainder':\n",
    "            # Handle the remainder case (those features that were passed through)\n",
    "            remainder_features = [input_features[i] for i in feature_indices]\n",
    "            output_features.extend(remainder_features)\n",
    "        else:\n",
    "            # Process transformed features\n",
    "            if hasattr(transformer, 'get_feature_names_out'):\n",
    "                feature_names = transformer.get_feature_names_out()\n",
    "                output_features.extend(feature_names)\n",
    "            else:\n",
    "                # If no method to get feature names, use the input feature names directly\n",
    "                output_features.extend(feature_indices)\n",
    "\n",
    "    return output_features\n",
    "\n",
    "# Assuming X contains all the original features\n",
    "input_features = X.columns.tolist()\n",
    "\n",
    "# Fetch feature names from the preprocessor using the revised function\n",
    "feature_names = get_feature_names(preprocessor, input_features)\n",
    "\n",
    "# Assuming best_pipeline is already fitted\n",
    "if hasattr(best_pipeline.named_steps['model'], 'feature_importances_'):\n",
    "    importances = best_pipeline.named_steps['model'].feature_importances_\n",
    "    feature_importances = pd.DataFrame({'feature': feature_names, 'importance': importances})\n",
    "    print(feature_importances.sort_values(by='importance', ascending=False))\n",
    "else:\n",
    "    print(\"The model is not fitted or does not support feature importance extraction.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming X, y, and the best_pipeline? have already been defined as shown in previous steps.\n",
    "\n",
    "# Splitting the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Re-train the best model found by Optuna on the training set\n",
    "best_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_pipeline.predict(X_test)\n",
    "\n",
    "# Calculate performance metrics\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = len(y_test)  # Number of observations\n",
    "p = X_test.shape[1]  # Number of features\n",
    "adjusted_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
    "\n",
    "# Print performance metrics\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"R-squared: {r2}\")\n",
    "print(f\"Adjusted R-squared: {adjusted_r2}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
